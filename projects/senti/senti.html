<html lang="en">

<head>
    
  <title>Unsupervised Sentiment Analysis</title>
  
  <meta charset="utf-8">
  <meta name="author" content="Yilin Wang">
  
  <link href="styles/asu.ico" rel="icon" />
  <link href="styles/reset.css" rel="stylesheet" >
  <link href="styles/senti_ins.css" rel="stylesheet" >
  <link href="styles/senti_mobile.css" rel="stylesheet"  media="only screen and (max-device-width: 480px)" >
  <link href="styles/lightbox.css" rel="stylesheet"   >
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1.11.0/jquery.min.js"></script>
  <script src="lightbox.min.js"></script>
  

 
</head>
 <script>
    $(document).ready(function(){
      $(".fakelink").click(function(){
        $(".bibref").slideToggle(600);
      });
    });
  </script>

<body>
  
  <div class="header">
    <tr>
      <img src="LOGO_MG.gif" alt="ASU Logo" />
      <h1>Unsupervised Sentiment Analysis for Social Media Images</h1>
      <h2>Yilin Wang&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Suhang Wang&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Jiliang Tang&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Huan Liu&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Baoxin Li</h2>
      <h3><i>Arizona State University</i></h3>
    </tr>
  </div>
  <hr class="mainhr">
  
  
  <section class="abstract">
    
    <header><i>Abstract</i></header>

    <p><i>Recently text-based sentiment prediction has been
extensively studied, while image-centric sentiment
analysis receives much less attention. In this paper,
we study the problem of understanding human
sentiments from large-scale social media images,
considering both visual content and contextual information,
such as comments on the images, captions,
etc. The challenge of this problem lies in
the &quot semantic gap &quot between low-level visual features
and higher-level image sentiments. Moreover,
the lack of proper annotations/labels in the majority
of social media images presents another challenge.
To address these two challenges, we propose
a novel Unsupervised SEntiment Analysis (USEA)
framework for social media images. Our approach
exploits relations among visual content and relevant
contextual information to bridge the  &quot semantic 
gap &quot in the prediction of image sentiments. With
experiments on two large-scale datasets, we show
that the proposed method is effective in addressing
the two challenges.</i></p>
    
  </section>
  
  <section class="toprow">
   <header><i>Overview</i></header>
  <table class="toprow">
    <tr>
      <td>negative (Flickr)</td>
      <td>neutral (Flickr)</td>
      <td>positive (Flickr)</td>
    </tr>
    <tr>
      <td><img src="Panorama1.jpg" alt="sad" height="342" width="442" /></a></td>
      <td><img src="Panorama2.jpg" alt="neutral" height="342" width="442"/></a></td>
      <td><img src="Panorama3.jpg" alt="happy"  height="342" width="442" /></a></td>
    </tr>
  </table>
  <p><b>Background:</b> Current methods of sentiment analysis for social media images include low-level visual feature based approaches, mid-level visual feature based
approaches, and deep learning based approaches. The vast majority
of existing methods are supervised, relying on labeled images
to train sentiment classifiers. Unfortunately, sentiment
labels are in general unavailable for social media images, and
it is too labor- and time-intensive to obtain labeled sets large
enough for robust training. In order to utilize the vast amount
of unlabeled social media images, an unsupervised approach
would be much more desirable. This paper studies <b> unsupervised
sentiment analysis.</b>
</p>
<p><b>Challenges:</b> Typically, visual features such as color histogram, brightness,
the presence of objects and visual attributes lack the
level of semantic meanings required by sentiment prediction.
In supervised case, label information could be directly utilized
to build the connection between the visual features and
the sentiment labels. Thus, unsupervised sentiment analysis
for social media images is inherently more challenging
than its supervised counterpart.</p>
    
  
  <section>
  
    <header>Method</header>
   
  <hr class="midhr">
     
    <center>
       <img src="Picture1.png"  style="width:904px;height:488px"; >
    </center>
         
 <p>          
In this paper, we study unsupervised sentiment analysis for
social media images with textual information by investigating
two related challenges: (1) how to model the interaction
between images and textual information systematically so as
to support sentiment prediction using both sources of information,
and (2) how to use textual information to enable unsupervised
sentiment analysis for social media images. In
addressing these two challenges, we propose a novel Unsupervised
SEntiment Analysis (USEA) framework, which performs
sentiment analysis for social media images in an unsupervised
fashion. Figure 1 schematically illustrates the difference
between the proposed unsupervised method and existing
supervised methods. Supervised methods use label information to learn a sentiment classifier; while the proposed method
does not assume the availability of label information but employ
auxiliary textual information. Our main contribution can
be summarized as below: 
<ul>
  <li>A principled approach to enable unsupervised sentiment
analysis for social media images. </li>
  <li>A novel unsupervised sentiment analysis framework
USEA for social media images, which captures visual
and textual information into a unifying model. To our
best knowledge, USEA is the first unsupervised sentiment
analysis framework for social media images; and</li>
  <li>Comparative studies and evaluations using datasets from
real-world social media image-sharing sites, documenting
the performance of USEA and leading existing methods,
serving as benchmark for further exploration</li>
</ul>
</p>    
 </section>

  <section>
 <header>Publication</header>
    <hr class="midhr">
    
    <p><span class="citation">Yilin Wang, Suhang Wang, Jiliang Tang, Huan Liu, Baoxin Li. "Unsupervised Sentiment Analysis for Social Media Images". In IJCAI, 2015.</span>&nbsp;<a href="http://yilinwang.org/papers/Paper158_UESA.pdf">[paper] </a><a class="fakelink">[bibtex]</a></p>
    
    <p class="bibref">@InProceedings{Wangy-etal15a,<br>&nbsp;&nbsp;author = {Yilin Wang and Suhang Wang and Jiliang Tang and Huan Liu and Baoxin Li},<br>&nbsp;&nbsp;title = {Unsupervised Sentiment Analysis for Social Media Images},<br>&nbsp;&nbsp;booktitle = {International Joint Conference on Artificial Intelligence (IJCAI)},<br>&nbsp;&nbsp;month = {June},<br>&nbsp;&nbsp;year = {2015}<br>}</p>
    
  </section>
  <section>
  <header>Download</header>
  <hr class="midhr">
  <p><span class="citation"> USEA (you see) </span>  release soon </p>
  <p><span class="citation"> Slides</span>  </p>
	
  </section>
</body>
</html>
